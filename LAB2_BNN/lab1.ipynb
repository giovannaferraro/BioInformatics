{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset\n",
    "path = \"/Users/giovanna/Desktop/Magistrale/SecondoAnno/AIBioInfo/Labs/LAB2_BNN/dataset_LUMINAL_A_B.csv\"\n",
    "test_df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first way to encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['l'] = test_df['l'].str.replace(r'\\s+', '', regex=True)\n",
    "label_mapping = {\n",
    "    'LuminalB': 1.0,\n",
    "    'LuminalA': 0.0,\n",
    "}\n",
    "\n",
    "test_df['l'] = test_df['l'].map(label_mapping)\n",
    "test_df = test_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract X and y from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = test_df['l']\n",
    "X = test_df.drop('l', axis=1)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split the dataset and scale train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now split dataset into train and test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing dimensionality reduction as the features are a lot and it's unfeaseable to train a model on such a huge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=80)\n",
    "X_train_pca = pca.fit_transform(X_train).astype(np.float32)\n",
    "X_test_pca = pca.transform(X_test).astype(np.float32)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transforming data from numpy to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = torch.from_numpy(X_train_pca)\n",
    "X_test_t = torch.from_numpy(X_test_pca)\n",
    "y_train_t = torch.from_numpy(y_train.values)\n",
    "y_test_t = torch.from_numpy(y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "test_dataset = TensorDataset(X_test_t, y_test_t)\n",
    "batchsize = 8\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batchsize, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BNN(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=80, out_features=200, bias=True)\n",
      "    (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=200, out_features=75, bias=True)\n",
      "    (5): BatchNorm1d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.3, inplace=False)\n",
      "    (8): Linear(in_features=75, out_features=1, bias=True)\n",
      "    (9): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_features = X_train_t.shape[1]\n",
    "hidden1 = 200\n",
    "hidden2 = 75\n",
    "output = 1\n",
    "\n",
    "class BNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(num_features, hidden1),\n",
    "            nn.BatchNorm1d(hidden1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(hidden1, hidden2),\n",
    "            nn.BatchNorm1d(hidden2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(hidden2, output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "\n",
    "model = BNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_acc(mlp: nn.Module, data_loader: torch.utils.data.DataLoader):\n",
    "  \n",
    "  correct = 0\n",
    "  total = 0\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for x, y in data_loader:\n",
    "      y_pred = model(x)\n",
    "      # print(y_pred)\n",
    "      y_pred_discr = torch.round(y_pred)\n",
    "      # print(y_pred_discr)\n",
    "      # print(y_pred.shape, y_pred_discr.shape, y.shape)\n",
    "      acc = torch.sum((y_pred_discr == y).float()) \n",
    "      correct += acc\n",
    "      total += y_pred.size(0)\n",
    "  \n",
    "  return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now starts the actual training of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train accuracy: 3.799999952316284 test accuracy: 3.700000047683716\n",
      "Epoch: 1 \tTraining Loss: 0.704822\n",
      "Epoch 1 train accuracy: 4.099999904632568 test accuracy: 3.700000047683716\n",
      "Epoch: 2 \tTraining Loss: 0.609487\n",
      "Epoch 2 train accuracy: 4.150000095367432 test accuracy: 3.5999999046325684\n",
      "Epoch: 3 \tTraining Loss: 0.485352\n",
      "Epoch 3 train accuracy: 3.875 test accuracy: 3.5999999046325684\n",
      "Epoch: 4 \tTraining Loss: 0.483693\n",
      "Epoch 4 train accuracy: 4.224999904632568 test accuracy: 3.700000047683716\n",
      "Epoch: 5 \tTraining Loss: 0.442454\n",
      "Epoch 5 train accuracy: 4.300000190734863 test accuracy: 3.700000047683716\n",
      "Epoch: 6 \tTraining Loss: 0.259077\n",
      "Epoch 6 train accuracy: 4.150000095367432 test accuracy: 3.5999999046325684\n",
      "Epoch: 7 \tTraining Loss: 0.338176\n",
      "Epoch 7 train accuracy: 4.199999809265137 test accuracy: 3.5\n",
      "Epoch: 8 \tTraining Loss: 0.274356\n",
      "Epoch 8 train accuracy: 4.349999904632568 test accuracy: 3.5999999046325684\n",
      "Epoch: 9 \tTraining Loss: 0.161795\n",
      "Epoch 9 train accuracy: 4.300000190734863 test accuracy: 3.5999999046325684\n",
      "Epoch: 10 \tTraining Loss: 0.168044\n",
      "Epoch 10 train accuracy: 4.25 test accuracy: 3.5999999046325684\n",
      "Epoch: 11 \tTraining Loss: 0.167213\n",
      "Epoch 11 train accuracy: 4.324999809265137 test accuracy: 3.5999999046325684\n",
      "Epoch: 12 \tTraining Loss: 0.128909\n",
      "Epoch 12 train accuracy: 4.449999809265137 test accuracy: 3.5999999046325684\n",
      "Epoch: 13 \tTraining Loss: 0.202757\n",
      "Epoch 13 train accuracy: 4.474999904632568 test accuracy: 3.5999999046325684\n",
      "Epoch: 14 \tTraining Loss: 0.089078\n",
      "Epoch 14 train accuracy: 4.550000190734863 test accuracy: 3.5999999046325684\n",
      "Epoch: 15 \tTraining Loss: 0.062872\n",
      "Epoch 15 train accuracy: 4.324999809265137 test accuracy: 3.5\n",
      "Epoch: 16 \tTraining Loss: 0.177237\n",
      "Epoch 16 train accuracy: 4.449999809265137 test accuracy: 3.5\n",
      "Epoch: 17 \tTraining Loss: 0.048586\n",
      "Epoch 17 train accuracy: 4.474999904632568 test accuracy: 3.5\n",
      "Epoch: 18 \tTraining Loss: 0.062945\n",
      "Epoch 18 train accuracy: 4.525000095367432 test accuracy: 3.5999999046325684\n",
      "Epoch: 19 \tTraining Loss: 0.046563\n",
      "Epoch 19 train accuracy: 4.425000190734863 test accuracy: 3.5999999046325684\n",
      "Epoch: 20 \tTraining Loss: 0.067503\n",
      "Epoch 20 train accuracy: 4.599999904632568 test accuracy: 3.5\n",
      "Epoch: 21 \tTraining Loss: 0.037052\n",
      "Epoch 21 train accuracy: 4.375 test accuracy: 3.5999999046325684\n",
      "Epoch: 22 \tTraining Loss: 0.038274\n",
      "Epoch 22 train accuracy: 4.425000190734863 test accuracy: 3.5\n",
      "Epoch: 23 \tTraining Loss: 0.071007\n",
      "Epoch 23 train accuracy: 4.175000190734863 test accuracy: 3.5\n",
      "Epoch: 24 \tTraining Loss: 0.048441\n",
      "Epoch 24 train accuracy: 4.650000095367432 test accuracy: 3.5\n",
      "Epoch: 25 \tTraining Loss: 0.056986\n",
      "Epoch 25 train accuracy: 4.449999809265137 test accuracy: 3.5999999046325684\n",
      "Epoch: 26 \tTraining Loss: 0.024169\n",
      "Epoch 26 train accuracy: 4.375 test accuracy: 3.5\n",
      "Epoch: 27 \tTraining Loss: 0.225950\n",
      "Epoch 27 train accuracy: 4.474999904632568 test accuracy: 3.5999999046325684\n",
      "Epoch: 28 \tTraining Loss: 0.014869\n",
      "Epoch 28 train accuracy: 4.425000190734863 test accuracy: 3.5\n",
      "Epoch: 29 \tTraining Loss: 0.055035\n",
      "Epoch 29 train accuracy: 4.625 test accuracy: 3.5999999046325684\n",
      "Epoch: 30 \tTraining Loss: 0.101268\n",
      "Epoch 30 train accuracy: 4.425000190734863 test accuracy: 3.5\n",
      "Epoch: 31 \tTraining Loss: 0.055033\n",
      "Epoch 31 train accuracy: 4.375 test accuracy: 3.5\n",
      "Epoch: 32 \tTraining Loss: 0.037686\n",
      "Epoch 32 train accuracy: 4.474999904632568 test accuracy: 3.5999999046325684\n",
      "Epoch: 33 \tTraining Loss: 0.012569\n",
      "Epoch 33 train accuracy: 4.25 test accuracy: 3.5999999046325684\n",
      "Epoch: 34 \tTraining Loss: 0.022617\n",
      "Epoch 34 train accuracy: 4.599999904632568 test accuracy: 3.5\n",
      "Epoch: 35 \tTraining Loss: 0.024903\n",
      "Epoch 35 train accuracy: 4.425000190734863 test accuracy: 3.5\n",
      "Epoch: 36 \tTraining Loss: 0.087445\n",
      "Epoch 36 train accuracy: 4.275000095367432 test accuracy: 3.5999999046325684\n",
      "Epoch: 37 \tTraining Loss: 0.045375\n",
      "Epoch 37 train accuracy: 4.375 test accuracy: 3.5\n",
      "Epoch: 38 \tTraining Loss: 0.049700\n",
      "Epoch 38 train accuracy: 4.550000190734863 test accuracy: 3.5\n",
      "Epoch: 39 \tTraining Loss: 0.013449\n",
      "Epoch 39 train accuracy: 4.375 test accuracy: 3.5999999046325684\n",
      "Epoch: 40 \tTraining Loss: 0.015875\n",
      "Epoch 40 train accuracy: 4.574999809265137 test accuracy: 3.5999999046325684\n",
      "Epoch: 41 \tTraining Loss: 0.021329\n",
      "Epoch 41 train accuracy: 4.525000095367432 test accuracy: 3.5999999046325684\n",
      "Epoch: 42 \tTraining Loss: 0.080322\n",
      "Epoch 42 train accuracy: 4.375 test accuracy: 3.5999999046325684\n",
      "Epoch: 43 \tTraining Loss: 0.245347\n",
      "Epoch 43 train accuracy: 4.275000095367432 test accuracy: 3.700000047683716\n",
      "Epoch: 44 \tTraining Loss: 0.007110\n",
      "Epoch 44 train accuracy: 4.275000095367432 test accuracy: 3.5999999046325684\n",
      "Epoch: 45 \tTraining Loss: 0.022586\n",
      "Epoch 45 train accuracy: 4.375 test accuracy: 3.5999999046325684\n",
      "Epoch: 46 \tTraining Loss: 0.015274\n",
      "Epoch 46 train accuracy: 4.550000190734863 test accuracy: 3.5999999046325684\n",
      "Epoch: 47 \tTraining Loss: 0.046166\n",
      "Epoch 47 train accuracy: 4.324999809265137 test accuracy: 3.5\n",
      "Epoch: 48 \tTraining Loss: 0.051196\n",
      "Epoch 48 train accuracy: 4.099999904632568 test accuracy: 3.5\n",
      "Epoch: 49 \tTraining Loss: 0.003019\n",
      "Epoch 49 train accuracy: 4.224999904632568 test accuracy: 3.5999999046325684\n",
      "Epoch: 50 \tTraining Loss: 0.004743\n",
      "Epoch 50 train accuracy: 4.875 test accuracy: 3.5\n",
      "Epoch: 51 \tTraining Loss: 0.006298\n",
      "Epoch 51 train accuracy: 4.574999809265137 test accuracy: 3.5\n",
      "Epoch: 52 \tTraining Loss: 0.006933\n",
      "Epoch 52 train accuracy: 4.775000095367432 test accuracy: 3.5\n",
      "Epoch: 53 \tTraining Loss: 0.007686\n",
      "Epoch 53 train accuracy: 4.625 test accuracy: 3.5\n",
      "Epoch: 54 \tTraining Loss: 0.006394\n",
      "Epoch 54 train accuracy: 4.900000095367432 test accuracy: 3.5999999046325684\n",
      "Epoch: 55 \tTraining Loss: 0.006819\n",
      "Epoch 55 train accuracy: 4.675000190734863 test accuracy: 3.5999999046325684\n",
      "Epoch: 56 \tTraining Loss: 0.007051\n",
      "Epoch 56 train accuracy: 4.175000190734863 test accuracy: 3.5999999046325684\n",
      "Epoch: 57 \tTraining Loss: 0.006080\n",
      "Epoch 57 train accuracy: 4.175000190734863 test accuracy: 3.5999999046325684\n",
      "Epoch: 58 \tTraining Loss: 0.010852\n",
      "Epoch 58 train accuracy: 4.574999809265137 test accuracy: 3.5\n",
      "Epoch: 59 \tTraining Loss: 0.029458\n",
      "Epoch 59 train accuracy: 4.324999809265137 test accuracy: 3.5999999046325684\n",
      "Epoch: 60 \tTraining Loss: 0.053538\n",
      "Epoch 60 train accuracy: 4.425000190734863 test accuracy: 3.5\n",
      "Epoch: 61 \tTraining Loss: 0.005087\n",
      "Epoch 61 train accuracy: 4.474999904632568 test accuracy: 3.5999999046325684\n",
      "Epoch: 62 \tTraining Loss: 0.017062\n",
      "Epoch 62 train accuracy: 4.324999809265137 test accuracy: 3.5999999046325684\n",
      "Epoch: 63 \tTraining Loss: 0.020901\n",
      "Epoch 63 train accuracy: 4.324999809265137 test accuracy: 3.5999999046325684\n",
      "Epoch: 64 \tTraining Loss: 0.005092\n",
      "Epoch 64 train accuracy: 4.699999809265137 test accuracy: 3.5999999046325684\n",
      "Epoch: 65 \tTraining Loss: 0.067732\n",
      "Epoch 65 train accuracy: 4.550000190734863 test accuracy: 3.5999999046325684\n",
      "Epoch: 66 \tTraining Loss: 0.004393\n",
      "Epoch 66 train accuracy: 4.574999809265137 test accuracy: 3.5\n",
      "Epoch: 67 \tTraining Loss: 0.002146\n",
      "Epoch 67 train accuracy: 4.324999809265137 test accuracy: 3.5999999046325684\n",
      "Epoch: 68 \tTraining Loss: 0.008675\n",
      "Epoch 68 train accuracy: 4.525000095367432 test accuracy: 3.5\n",
      "Epoch: 69 \tTraining Loss: 0.008915\n",
      "Epoch 69 train accuracy: 4.425000190734863 test accuracy: 3.5999999046325684\n",
      "Epoch: 70 \tTraining Loss: 0.002853\n",
      "Epoch 70 train accuracy: 4.574999809265137 test accuracy: 3.5\n",
      "Epoch: 71 \tTraining Loss: 0.004660\n",
      "Epoch 71 train accuracy: 4.425000190734863 test accuracy: 3.5\n",
      "Epoch: 72 \tTraining Loss: 0.127292\n",
      "Epoch 72 train accuracy: 4.425000190734863 test accuracy: 3.5\n",
      "Epoch: 73 \tTraining Loss: 0.007861\n",
      "Epoch 73 train accuracy: 4.449999809265137 test accuracy: 3.5\n",
      "Epoch: 74 \tTraining Loss: 0.010280\n",
      "Epoch 74 train accuracy: 4.550000190734863 test accuracy: 3.5999999046325684\n",
      "Epoch: 75 \tTraining Loss: 0.005825\n",
      "Epoch 75 train accuracy: 4.474999904632568 test accuracy: 3.5999999046325684\n",
      "Epoch: 76 \tTraining Loss: 0.009930\n",
      "Epoch 76 train accuracy: 4.425000190734863 test accuracy: 3.5\n",
      "Epoch: 77 \tTraining Loss: 0.010554\n",
      "Epoch 77 train accuracy: 4.275000095367432 test accuracy: 3.5\n",
      "Epoch: 78 \tTraining Loss: 0.008055\n",
      "Epoch 78 train accuracy: 4.574999809265137 test accuracy: 3.5\n",
      "Epoch: 79 \tTraining Loss: 0.010370\n",
      "Epoch 79 train accuracy: 4.275000095367432 test accuracy: 3.5\n",
      "Epoch: 80 \tTraining Loss: 0.021117\n",
      "Epoch 80 train accuracy: 4.074999809265137 test accuracy: 3.5\n",
      "Epoch: 81 \tTraining Loss: 0.006845\n",
      "Epoch 81 train accuracy: 4.425000190734863 test accuracy: 3.5\n",
      "Epoch: 82 \tTraining Loss: 0.002088\n",
      "Epoch 82 train accuracy: 4.175000190734863 test accuracy: 3.5999999046325684\n",
      "Epoch: 83 \tTraining Loss: 0.012328\n",
      "Epoch 83 train accuracy: 4.525000095367432 test accuracy: 3.5\n",
      "Epoch: 84 \tTraining Loss: 0.001148\n",
      "Epoch 84 train accuracy: 4.275000095367432 test accuracy: 3.5999999046325684\n",
      "Epoch: 85 \tTraining Loss: 0.447469\n",
      "Epoch 85 train accuracy: 4.525000095367432 test accuracy: 3.5\n",
      "Epoch: 86 \tTraining Loss: 0.003557\n",
      "Epoch 86 train accuracy: 4.650000095367432 test accuracy: 3.5999999046325684\n",
      "Epoch: 87 \tTraining Loss: 0.002048\n",
      "Epoch 87 train accuracy: 4.324999809265137 test accuracy: 3.5\n",
      "Epoch: 88 \tTraining Loss: 0.010931\n",
      "Epoch 88 train accuracy: 4.375 test accuracy: 3.5999999046325684\n",
      "Epoch: 89 \tTraining Loss: 0.102064\n",
      "Epoch 89 train accuracy: 4.275000095367432 test accuracy: 3.5999999046325684\n",
      "Epoch: 90 \tTraining Loss: 0.008830\n",
      "Epoch 90 train accuracy: 4.125 test accuracy: 3.5999999046325684\n",
      "Epoch: 91 \tTraining Loss: 0.004061\n",
      "Epoch 91 train accuracy: 4.074999809265137 test accuracy: 3.5\n",
      "Epoch: 92 \tTraining Loss: 0.002041\n",
      "Epoch 92 train accuracy: 4.525000095367432 test accuracy: 3.5\n",
      "Epoch: 93 \tTraining Loss: 0.002297\n",
      "Epoch 93 train accuracy: 4.625 test accuracy: 3.5999999046325684\n",
      "Epoch: 94 \tTraining Loss: 0.008308\n",
      "Epoch 94 train accuracy: 4.349999904632568 test accuracy: 3.5\n",
      "Epoch: 95 \tTraining Loss: 0.006851\n",
      "Epoch 95 train accuracy: 4.574999809265137 test accuracy: 3.5999999046325684\n",
      "Epoch: 96 \tTraining Loss: 0.001039\n",
      "Epoch 96 train accuracy: 4.525000095367432 test accuracy: 3.5\n",
      "Epoch: 97 \tTraining Loss: 0.013976\n",
      "Epoch 97 train accuracy: 4.625 test accuracy: 3.5999999046325684\n",
      "Epoch: 98 \tTraining Loss: 0.005234\n",
      "Epoch 98 train accuracy: 4.425000190734863 test accuracy: 3.5\n",
      "Epoch: 99 \tTraining Loss: 0.002005\n",
      "Epoch 99 train accuracy: 4.425000190734863 test accuracy: 3.5999999046325684\n",
      "Epoch: 100 \tTraining Loss: 0.010555\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "train_loss = []\n",
    "\n",
    "try:\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch} train accuracy: {eval_acc(model, train_dataloader)} \"\n",
    "                f\"test accuracy: {eval_acc(model, test_dataloader)}\")\n",
    "\n",
    "        #Within each epoch run the subsets of data = batch sizes.\n",
    "        for x_batch, y_batch in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x_batch)\n",
    "            y_pred = y_pred.view(-1)\n",
    "            y_pred = y_pred.float()\n",
    "            y_batch = y_batch.float()\n",
    "            # print(\"dim output nel train\", y_pred.shape, y_batch.shape)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, loss.item()))\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
